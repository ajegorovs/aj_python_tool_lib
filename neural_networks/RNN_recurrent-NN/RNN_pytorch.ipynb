{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, re\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#tensorboard --logdir 'runs\\RNN_torch' --host localhost --port 8888\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "import datetime\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 1975 words of size 8, and 50 unique characters.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Chars: g D P m L A K F z j p U Z h u N e J k Y B r x C f o c d v t G M n i T I q l H W O E s y a R w b V S'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = open(os.path.join('data_processing','media','tinyshakespeare.txt'), 'r').read() # should be simple plain text file\n",
    "data = re.sub(r'[^a-zA-Z\\s]', '', data) # remove non-alphabet\n",
    "seq_length = 8\n",
    "words_all = data.split()\n",
    "words = list(set([w for w in words_all if len(w) == seq_length]))\n",
    "chars_all = [c for w in words for c in w] #[*data]\n",
    "chars = list(set(chars_all))  #list(set(data))\n",
    "data_size, vocab_size = len(words), len(chars)\n",
    "print('data has %d words of size %d, and %d unique characters.' % (len(words), seq_length, vocab_size))\n",
    "'Chars: ' + ' '.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sorted chars: e s r i n t a o d l c u g h p m f b y v w k C S A R M I q E B T D P L O j x N U H F z W V G K J Y Z'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency = dict(Counter(chars_all))\n",
    "vocab_unique = list(sorted(frequency.keys(), key=lambda x: frequency[x], reverse=True))\n",
    "char_to_ix = { ch:i for i,ch in enumerate(vocab_unique) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(vocab_unique) }\n",
    "'Sorted chars: ' + ' '.join(vocab_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d', 'i', 'r', 'e', 'c', 't', 'l', 'y']\n",
      "[8, 3, 2, 0, 10, 5, 9, 18]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def oneHotEncode(chars: List[str]) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "        lets hold encoded vectors as columns\n",
    "    \"\"\"\n",
    "    encode = torch.zeros(len(chars),vocab_size)\n",
    "    x,y = torch.tensor([(i,char_to_ix[a]) for i,a in enumerate(chars)]).T\n",
    "    encode[x,y] = 1\n",
    "    return encode.T\n",
    "split_word = [*words[0]];print(split_word)\n",
    "word_index = [char_to_ix[a] for a in split_word];print(word_index)\n",
    "oneHotEncode(split_word)[:10,:].to(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i2s(inp):\n",
    "    # index to string\n",
    "    pos = torch.topk(inp, dim = 1, k = 1)[1].view(-1)\n",
    "    return ''.join([ix_to_char[int(i)] for i in pos]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 8, 50])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changed char columns to rows\n",
    "num_words_max = 40\n",
    "X_train = torch.zeros(size=(num_words_max, seq_length, vocab_size), device=device) # words, chars, seq of chars\n",
    "for i in range(num_words_max):\n",
    "    X_train[i] = oneHotEncode(words[i]).T\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wordsDataset(Dataset):\n",
    "    def __init__(self, data_in):\n",
    "        self.x = data_in\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.x[idx])[:-1], (self.x[idx])[1:]\n",
    "\n",
    "dataset = wordsDataset(X_train)\n",
    "BATCH_SIZE = 1\n",
    "data_loader_train   = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.hidden_size= hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn        = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc         = nn.Linear(hidden_size, output_size)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        hidden =  torch.zeros(1, self.hidden_size).to(device)#x.size(0)\n",
    "        out, h = self.rnn(x, hidden)\n",
    "        y = torch.softmax(self.fc(out),dim=1)\n",
    "        #print(torch.allclose( out[[-1]], h )) # >>> True\n",
    "        return y, h\n",
    "    \n",
    "    @torch.no_grad\n",
    "    def predict(self, x, hidden ):\n",
    "        out, h = self.rnn(x, hidden)\n",
    "        y = torch.softmax(self.fc(out),dim=1)\n",
    "        return y, h\n",
    "\n",
    "hidden_size = 150 \n",
    "net = SimpleRNN(input_size = vocab_size, hidden_size = hidden_size, \n",
    "                num_layers = 1, output_size = vocab_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  left  | right  |  guess  \n",
      "---------------------------\n",
      "Childre_|_hildren|_oildren|\n",
      "singula_|_ingular|_onguVar|\n",
      "prettil_|_rettily|_rottily|\n",
      "chaplai_|_haplain|_roplain|\n",
      "enointe_|_nointed|_nointed|\n",
      "Benvoli_|_envolio|_envJlio|\n",
      "Conside_|_onsider|_onsider|\n",
      "unsever_|_nseverd|_nsqverd|\n",
      "meeting_|_eetings|_eetings|\n",
      "Bequeat_|_equeath|_engmjth|\n",
      "returns_|_eturnst|_emfrnst|\n",
      "remembe_|_emember|_emember|\n",
      "directl_|_irectly|_erectly|\n",
      "bruisin_|_ruising|_rwIsing|\n",
      "Flander_|_landers|_landers|\n",
      "quaintl_|_uaintly|_uaintly|\n",
      "LUCENTI_|_UCENTIO|_UCENTIO|\n",
      "pickloc_|_icklock|_rclloJk|\n",
      "misgive_|_isgives|_eUgives|\n",
      "ravenou_|_avenous|_ebenous|\n",
      "soldier_|_oldiers|_oldiers|\n",
      "publicl_|_ublicly|_rblicly|\n",
      "Howling_|_owlings|_owlings|\n",
      "overcom_|_vercome|_uercgme|\n",
      "grinnin_|_rinning|_renning|\n",
      "thinkin_|_hinking|_hinking|\n",
      "greates_|_reatest|_renteZt|\n",
      "Standin_|_tanding|_tanding|\n",
      "delicat_|_elicate|_elicate|\n",
      "outstri_|_utstrip|_utsAOip|\n",
      "forcefu_|_orceful|_orceful|\n",
      "Welshma_|_elshman|_elsHman|\n",
      "Beaumon_|_eaumond|_envmond|\n",
      "standin_|_tanding|_oanding|\n",
      "crownin_|_rowning|_rowning|\n",
      "prologu_|_rologue|_rologue|\n",
      "majesty_|_ajestys|_eUestys|\n",
      "infusio_|_nfusion|_naukion|\n",
      "hungerl_|_ungerly|_ungOrly|\n",
      "Reproac_|_eproach|_eprotch|\n",
      "epoch: 15300, loss: 123.791"
     ]
    }
   ],
   "source": [
    "num_epochs = 15301\n",
    "criterion = nn.CrossEntropyLoss()#nn.MSELoss()\n",
    "optimizer = Adam(net.parameters(), lr = 1e-3)#, weight_decay=1e-5)\n",
    "now = datetime.datetime.now()\n",
    "s2 = now.strftime(\"%H_%M_%S\")\n",
    "writer = SummaryWriter(fr'runs/RNN_torch/{s2}')\n",
    "step = 0\n",
    "top = f'{\"left\":^{seq_length}}|{\"right\":^{seq_length}}|{\"guess\":^{seq_length+1}}'\n",
    "top2 = '-'*len(top)\n",
    "for i in range(num_epochs):\n",
    "    \n",
    "    loss2 = 0\n",
    "    if i % (num_epochs//5) == 0:\n",
    "        print(top);print(top2)\n",
    "    for x,y in data_loader_train:\n",
    "        x = x.squeeze(0)    # (seq_len - 1, len_vocab)\n",
    "        y = y.squeeze(0)\n",
    "        output, hidden = net(x)\n",
    "        loss   = criterion(output, y)\n",
    "        loss2 += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % (num_epochs//5) == 0:\n",
    "            ss = i2s(x) + '_|_' + i2s(y) + '|_'  + i2s(output) + '|' \n",
    "            print(ss)\n",
    "            \n",
    "    if i % (num_epochs//5) == 0:\n",
    "        print(f'epoch: {str(i):<4}, loss: {loss2:0.3f}', end=\"\")\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "    writer.add_scalar('Training Loss', loss2, global_step=step)\n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supply RNN **first_n_chars** first characters of a word to generate a hidden state.<br>\n",
    "It will generate first prediction. Use hidden state to iterate forward and update state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole word; guess: (given)(1st guess)rest\n",
      "prettily; guess: (pre)(t)tily\n",
      "ravenous; guess: (rav)(e)nous\n",
      "Bequeath; guess: (Beq)(c)mond\n",
      "enointed; guess: (eno)(i)nted\n",
      "soldiers; guess: (sol)(d)iers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 8, 50])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changed from original in 'neural_networks/RNN_recurrent-NN/RNN_from_scratch.ipynb'\n",
    "def test(input, num_words = 5, first_n_chars = 1):\n",
    "    shuffle_idx = torch.randperm(len(input))[:num_words]\n",
    "    for i in shuffle_idx:\n",
    "        word = input[i]\n",
    "\n",
    "        # store known word start in solution\n",
    "        store = torch.zeros_like(word, device=device)\n",
    "        store[:first_n_chars] = word[:first_n_chars]\n",
    "\n",
    "        \n",
    "        # generate hidden state for known part\n",
    "        hidden =  torch.zeros(1, hidden_size).to(device)\n",
    "        prediction, hidden_state = net.predict(word[:first_n_chars], hidden)\n",
    "        prediction = prediction[[-1]]\n",
    "        store[[first_n_chars]] = prediction\n",
    "    \n",
    "        word_whole = i2s(word)\n",
    "        word_start = i2s(word[:first_n_chars])\n",
    "        word_guess_1 = i2s(prediction)    \n",
    "    \n",
    "        # continue predicting next chars based on latest hidden state\n",
    "        for i in range(first_n_chars + 1, store.size(0)):\n",
    "            prediction, hidden_state = net.predict(prediction, hidden_state)\n",
    "            store[[i]] = prediction\n",
    "            #prediction, hidden_state = net.predict(store[:i], hidden_state)\n",
    "            #store[[i]] = prediction[[-1]]\n",
    "\n",
    "        outp    =  word_whole + '; guess: ('\n",
    "        outp += word_start + ')' + f'({word_guess_1})'\n",
    "        outp += i2s(store[first_n_chars+1:])\n",
    "\n",
    "        print(outp)\n",
    "    return\n",
    "    \n",
    "print('whole word; guess: (given)(1st guess)rest')\n",
    "test(X_train, num_words = 5, first_n_chars = 3)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
