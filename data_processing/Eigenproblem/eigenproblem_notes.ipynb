{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from misc_tools.print_latex import print_tex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix equation \n",
    "$$A\\vec{x} = \\vec{b}$$\n",
    "can be interpreted as $A$ being a matrix transformation that acts on a vector $\\vec{v}$ and produces $\\vec{b}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit of digression from main topic. \n",
    "\n",
    "Equation $A\\vec{x} = \\vec{b}$ can be interpreted as finding linear combinations of columns of $A$ with coefficients contained in $\\vec{x}$\n",
    "$$A\\vec{x} =\n",
    "\\begin{bmatrix}\n",
    "a_{11} & a_{12} \\\\ a_{21} & a_{22} \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\alpha \\\\ \\beta\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "\\vec{A}_1 & \\vec{A}_2\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\alpha \\\\ \\beta\n",
    "\\end{bmatrix}=\n",
    "\\alpha \\vec{A}_1 + \\beta\\vec{A}_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this interpretation we can encounter matrices $A$ where columns are linearly dependant, in which case arbitrary $\\vec{b}$ cannot be constructed via linear combination. \n",
    "\n",
    "In other words -  \"columns of $A$ dont span space of $\\vec{b}$\"\n",
    "\n",
    "Such matrices can be determined by examining their 'rank' or by calculating their determinant.\n",
    "\n",
    "Consider $A$ with linearly dependant columns as\n",
    "\n",
    "$$A = \\begin{bmatrix}\n",
    "\\vec{A}_1 & \\alpha \\cdot \\vec{A}_2\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "a & \\alpha \\cdot a \\\\ b & \\alpha \\cdot  b\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "determinant is\n",
    "\n",
    "$$|A| = \\alpha \\cdot  a \\cdot b - \\alpha \\cdot  b \\cdot a = 0$$\n",
    "\n",
    "Any matrices that have determinant of zero are called 'singular'.\n",
    "\n",
    "<u>Main takeaway is that columns of a singular matrix are linearly dependant.</u>\n",
    "\n",
    "*   Dependant columns of a matrix reduce the space which they can span. \n",
    "\n",
    "*   Space which 'can be explored' is determined by matrices 'rank'. \n",
    "\n",
    "*   Remaining space is 'discarded' by producing maps to zero space (called 'kernel' or 'nullspace').\n",
    "\n",
    "https://en.wikipedia.org/wiki/Rank%E2%80%93nullity_theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\begin{bmatrix} 1 & 1/2 \\\\ 2 & 1 \\end{bmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.linalg.det(A) = 0.0\n"
     ]
    }
   ],
   "source": [
    "A1 = np.array([[1,2]]).T\n",
    "alpha = 0.5\n",
    "A2 = alpha * A1\n",
    "A = np.hstack((A1, A2))\n",
    "print_tex(A) \n",
    "print(f'{np.linalg.det(A) = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we search for a problem where transformation produces vectors that are collinear to original vectors\n",
    "$$A\\vec{v} = \\lambda \\vec{v}$$\n",
    "\n",
    "set of of vectors that satisfy this problem are called _eigenvectors_ and their scaling constants are called _eigenvalues._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can rewrite this equation into a form\n",
    "$$A\\vec{v} - \\lambda \\vec{v} = \\vec{0}$$\n",
    "$$\\underbrace{(A - \\lambda I) }_{A^\\prime}\\vec{v} = \\vec{0}$$\n",
    "notice that this expression is also a linear transformation on $\\vec{v}$\n",
    "$$A^\\prime\\vec{v} = \\vec{0}$$\n",
    "Except we are mapping vectors onto zero vectors. \n",
    "***\n",
    "In a 'healthy' transformation, like scaling and rotation, only zero vectors map onto zero vectors $A \\vec{0} = \\vec{0}$. We call this solution case __trivial__.\n",
    "\n",
    "We can take step back and rephrase it: \"_only way to produce zero (vector) using combination of columns of A, is to have all coefficients being zero_\". \n",
    "***\n",
    "An 'unhealthy' transformation, will have a solution with non-zero coefficients. Accidentally, as we have discussed, if matrix $A$ has linearly dependant columns, it is 'singular' and has determinant of zero.\n",
    "***\n",
    "In our problem\n",
    "$$A^\\prime\\vec{v} = \\vec{0} = (A - \\lambda I)\\vec{v} = \\vec{0}$$\n",
    "We search for such __non-trivial__ solutions $\\vec{v}_i$ which will map to zero vectors. \n",
    "\n",
    "Under proper selection of $\\lambda_i$ values, matrix $A^\\prime(\\lambda) = (A - \\lambda I)$ becomes singular and will yield non-trivial result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we ask for \n",
    "$$|A - \\lambda I| = 0$$\n",
    "\n",
    "for example\n",
    "\n",
    "$$A = \n",
    "\\begin{bmatrix}\n",
    "3 & 2\\\\ 2 & 6\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[3,2],[2,6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$|A - \\lambda I| = \\bigg|\n",
    "\\begin{matrix}\n",
    "3- \\lambda& 2\\\\ 2 & 6-\\lambda\n",
    "\\end{matrix}\n",
    "\\bigg|=\n",
    "\n",
    "\\lambda^2 - 9\\lambda + 14 = (\\lambda - 7)(\\lambda - 2) = 0\n",
    "$$\n",
    "\n",
    "We see that we have two solutions $\\lambda_1 = 7$ and $\\lambda_2 = 2$, which are two eigenvalues.\n",
    "\n",
    "To find eigenvectors we calculate two cases:\n",
    "***\n",
    "$\\lambda_1 = 7:$\n",
    "$$(A - \\lambda_1 I)\\vec{v}_1 = \\vec{0}$$\n",
    "$$\\begin{bmatrix}\n",
    "-4 & 2\\\\ 2 & -1\n",
    "\\end{bmatrix}\\vec{v}_1 = \\vec{0}$$\n",
    "$$\\begin{matrix}\n",
    "-4 v_{11} &=& -2 v_{12}\\\\ 2v_{11} &=& v_{12}\n",
    "\\end{matrix}\\rightarrow \\vec{v}_1 = [v_{11}, 2v_{11}]^T = v_{11}[1,2]^T\n",
    "$$\n",
    "***\n",
    "$\\lambda_2 = 2:$\n",
    "$$(A - \\lambda_2 I)\\vec{v}_2 = \\vec{0}$$\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "1 & 2\\\\ 2 & 4\n",
    "\\end{bmatrix}\\vec{v}_2 = \\vec{0}$$\n",
    "$$\\begin{matrix}\n",
    "1 v_{21} &=& -2 v_{22}\\\\ 2v_{21} &=& -4 v_{22}\n",
    "\\end{matrix}\\rightarrow\\vec{v}_2 = [-2v_{22}, v_{22}]^T = v_{22}[-2,1]^T$$\n",
    "\n",
    "can set $v_{11} = v_{22} = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\lambda_1, \\lambda_2 = \\begin{bmatrix} 2 & 7 \\end{bmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle [\\vec{v}_1, \\vec{v}_2] = \\begin{bmatrix} -2 & -1 \\\\ 1 & -2 \\end{bmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eig_system_d = np.linalg.eig(A)._asdict()\n",
    "evecs = eig_system_d['eigenvectors'].copy()\n",
    "evecs/=evecs[1,0]\n",
    "print_tex('\\lambda_1, \\lambda_2 = ', eig_system_d['eigenvalues'])\n",
    "print_tex(r'[\\vec{v}_1, \\vec{v}_2] = ', evecs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Changing length of an eigenvector still keeps it an eigenvector, even eigenvalue does not have to be rescaled.\n",
    "\n",
    "Given the following is true: $$A\\vec{v}_1 = \\lambda_1 \\vec{v}_1$$\n",
    "we define a rescaled vector and apply $A$\n",
    "$$\\hat{\\vec{v}_1} = \\frac{\\vec{v}_1}{|| \\vec{v}_1||}$$\n",
    "$$A\\hat{\\vec{v}_1} = \\frac{A \\vec{v}_1}{|| \\vec{v}_1||} = \\frac{\\lambda_1 \\vec{v}_1}{|| \\vec{v}_1||} = \\lambda_1 \\hat{\\vec{v}_1}$$\n",
    "and see that OG expression is still satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "We can see that eigenvectors are orthogonal:\n",
    "$$\\vec{v}_1 \\cdot \\vec{v}_2 = -2 + 2 = 0$$\n",
    "So they are viable for constructing orthogonal coordinate system. \n",
    "\n",
    "Our choice for $v_{11}$ and $v_{22}$ could be made such as to make new basis vectors of unit length, thus forming _orthonormal_ coordinate system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle dot(\\begin{bmatrix} -2 & 1 \\end{bmatrix}\\begin{bmatrix} -1 & -2 \\end{bmatrix})=0$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vecs = evecs.T\n",
    "print_tex(f'dot(', *vecs, ')=', np.dot(*vecs)) # cols to rows and open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf\n",
    "\n",
    "Mentions interested aspects from spectral theory when $A$ is applied repeatedly.\n",
    "\n",
    "We can decompose any vector into a basis of eigenvectors\n",
    "\n",
    "$$\\vec{d} = \\alpha \\vec{v}_1 + \\beta \\vec{v}_2$$\n",
    "\n",
    "We know that\n",
    "\n",
    "$$A \\alpha \\vec{v}_1 = \\alpha \\lambda_1 \\vec{v}_1 $$\n",
    "so\n",
    "$$A\\vec{d} = A(\\alpha \\vec{v}_1 + \\beta \\vec{v}_2) = \\alpha \\lambda_1 \\vec{v}_1 + \\beta \\lambda_2 \\vec{v}_2$$\n",
    "and \n",
    "$$A^2 \\vec{d} = A(A\\vec{d} ) = \\alpha \\lambda_1^2 \\vec{v}_1 + \\beta \\lambda_2^2 \\vec{v}_2$$\n",
    "Depending on eigenvalues of $A$, by performing repeated application of transformation, we can expected $\\vec{d}$ to either shrink or grow infinitely.\n",
    "\n",
    "This is important aspect of iterative methods, where such transformations are common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.89442719, -0.4472136 ],\n",
       "       [ 0.4472136 , -0.89442719]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_system_d['eigenvectors']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
