{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from misc_tools.print_latex import print_tex\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paper: https://arxiv.org/pdf/1710.10903.pdf\n",
    "\n",
    "pytorch source: https://nn.labml.ai/graphs/gat/index.html\n",
    "\n",
    "* features $\\vec{h}_i$ -> colums\n",
    "* $\\vec{h}_i$ -> matrix H\n",
    "\n",
    "$$H=\n",
    "\\begin{bmatrix}\n",
    "\\vec{h}_1 & \\vec{h}_2 & \\dots\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\vec{h}_0 = \\begin{bmatrix} 0 \\\\ 1/2 \\end{bmatrix}; \\vec{h}_1 = \\begin{bmatrix} 1 \\\\ 3/2 \\end{bmatrix}; H = \\begin{bmatrix} 0 & 1 \\\\ 1/2 & 3/2 \\end{bmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_NODES,N_FEATS = 2,2\n",
    "H = 0.5*torch.arange(N_NODES*N_FEATS, dtype = float).view(N_NODES, N_FEATS).T\n",
    "print_tex(r'\\vec{h}_0 = ', H[:,[0]].numpy(), r'; \\vec{h}_1 = ', H[:,[1]].numpy(), '; H = ', H.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* embed $\\vec{h}_i$ into $\\vec{g}_i$ via $W$\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle W = \\begin{bmatrix} 2 & 0 \\\\ 0 & 2 \\end{bmatrix}; G = HW = \\begin{bmatrix} 0 & 2 \\\\ 1 & 3 \\end{bmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "W1 = 2*torch.eye(N_FEATS, dtype=H.dtype)\n",
    "G = W1 @ H\n",
    "print_tex('W = ', W1.numpy(),'; G = HW = ', G.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* make pairwise concatenation matrix $C$\n",
    "$$G = \n",
    "\\begin{bmatrix}\n",
    "\\vec{g}_1 &\n",
    "\\vec{g}_2 & \\dots\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$C = \n",
    "\\begin{bmatrix}\n",
    "\\vec{g}_1||\\vec{g}_1 &  \\vec{g}_1||\\vec{g}_2 \\\\\n",
    "\\vec{g}_2||\\vec{g}_1 &  \\vec{g}_2||\\vec{g}_2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "cannot broadcast, have to concat all elements. If we flatten:\n",
    "$$C_{flat} = \n",
    "\\begin{bmatrix}\n",
    "\\vec{g}_1||\\vec{g}_1 & \\vec{g}_1||\\vec{g}_2 &\n",
    "\\vec{g}_2||\\vec{g}_1 & \\vec{g}_2||\\vec{g}_2\n",
    "\\end{bmatrix}\n",
    "\\approx\n",
    "\\begin{bmatrix}\n",
    "\\vec{g}_1 &  \\vec{g}_1 &\n",
    "\\vec{g}_2 &  \\vec{g}_2\n",
    "\\end{bmatrix}\n",
    "||\n",
    "\\begin{bmatrix}\n",
    "\\vec{g}_1 &  \\vec{g}_2 &\n",
    "\\vec{g}_1 &  \\vec{g}_2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "So its element-wise concat. Observe ordering of both vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\vec{g}_0 = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}; \\vec{g}_1 = \\begin{bmatrix} 2 \\\\ 3 \\end{bmatrix}; C_{flat} = \\begin{bmatrix} 0 & 0 & 2 & 2 \\\\ 1 & 1 & 3 & 3 \\\\ 0 & 2 & 0 & 2 \\\\ 1 & 3 & 1 & 3 \\end{bmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g1      = torch.repeat_interleave(G, N_NODES, dim = 1)  # h1,h1,h1,h2,h2,h2,h3,...\n",
    "g2      = torch.tile(G, dims=(1,2))                     # h1,h2,h3,h1,h2,h3,h1,...\n",
    "C_f     = torch.cat((g1,g2), dim = 0)\n",
    "print_tex(r'\\vec{g}_0 = ', G[:,[0]].numpy(), r'; \\vec{g}_1 = ', G[:,[1]].numpy(), '; C_{flat} = ',C_f.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* repack into form where each concatenated feature can be dot-multiplied by attention vector $\\vec{a} \\in \\R^{2F \\times 1}$\n",
    "\n",
    "$\\vec{C_{i,j}} = (\\vec{g}_i||\\vec{g}_j) \\in \\R^{2F \\times 1}$ a column vector\n",
    "\n",
    "$$\\vec{a}^T = \n",
    "\\begin{bmatrix}\n",
    "a_1 & a_2 & \\dots & a_{2F}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "technically, i could keep this $C \\in \\R^{[2F \\times  N^2]}$ matrix:\n",
    "$$E = \n",
    "\\vec{a}^T\n",
    "\\begin{bmatrix}\n",
    "\\vec{C_{1,1}} & \\vec{C_{1,2}} & \\vec{C_{2,1}} &  \\vec{C_{2,2}}\n",
    "\\end{bmatrix}=\n",
    "\n",
    "\\begin{bmatrix}\n",
    "\\vec{a}^T\\vec{C_{1,1}} & \\vec{a}^T\\vec{C_{1,2}} & \\vec{a}^T\\vec{C_{2,1}} &  \\vec{a}^T\\vec{C_{2,2}}\n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "e_{1,1} & e_{1,2} & e_{2,1} & e_{2,2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "or i can cast it into shape ${[N \\times N  \\times 2F \\times 1]}$, which will be the same layout as adjacency matrix:\n",
    "$$\n",
    "C = \n",
    "\\begin{bmatrix}\n",
    "\\vec{C_{1,1}} & \\vec{C_{1,2}} \\\\ \\vec{C_{2,1}} &  \\vec{C_{2,2}}\n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0 \\\\ 1 \\\\ 0 \\\\ 1\n",
    "\\end{bmatrix}\n",
    "& \n",
    "\\begin{bmatrix}\n",
    "0 \\\\ 1 \\\\ 2 \\\\ 3\n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "2 \\\\ 3 \\\\ 0 \\\\ 1\n",
    "\\end{bmatrix}\n",
    "& \n",
    "\\begin{bmatrix}\n",
    "2 \\\\ 3 \\\\ 2 \\\\ 3\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Cast $\\vec{a}^T$ to shape ${[1 \\times 1  \\times 2F \\times 1]}$ for broadcasting(reminder) to  <br>\n",
    "match C shape ${[N \\times N  \\times 2F \\times 1]}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\vec{C}_{1,1} = \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 1 \\end{bmatrix}\\vec{C}_{1,2} = \\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 3 \\end{bmatrix}\\vec{C}_{2,1} = \\begin{bmatrix} 2 \\\\ 3 \\\\ 0 \\\\ 1 \\end{bmatrix}\\vec{C}_{2,2} = \\begin{bmatrix} 2 \\\\ 3 \\\\ 2 \\\\ 3 \\end{bmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "C = C_f.T.reshape(N_NODES,N_NODES, 2*N_FEATS,1);C\n",
    "print_tex(r'\\vec{C}_{1,1} = ', C[0,0].numpy(),r'\\vec{C}_{1,2} = ', C[0,1].numpy(),r'\\vec{C}_{2,1} = ', C[1,0].numpy(),r'\\vec{C}_{2,2} = ', C[1,1].numpy(),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can test broadcasting by element-picker vector. \n",
    "\n",
    "i.e $\\vec{a}^T$ = [1,0,0,0] $\\rightarrow \\vec{a}^T \\vec{C_{1,1}} = (\\vec{C_{1,1}})_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle element \\ 0 \\ of \\ C_(i,j)\\begin{bmatrix} 0 & 0 \\\\ 2 & 2 \\end{bmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle element \\ 1 \\ of \\ C_(i,j)\\begin{bmatrix} 1 & 1 \\\\ 3 & 3 \\end{bmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle element \\ 2 \\ of \\ C_(i,j)\\begin{bmatrix} 0 & 2 \\\\ 0 & 2 \\end{bmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle element \\ 3 \\ of \\ C_(i,j)\\begin{bmatrix} 1 & 3 \\\\ 1 & 3 \\end{bmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C.shape = torch.Size([2, 2, 4, 1])\n",
      "a.shape = torch.Size([1, 1, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "diag = torch.eye(2*N_FEATS).to(C.dtype)\n",
    "for i,a in enumerate(diag):\n",
    "    a = a.reshape(1,1,2*N_FEATS,1).transpose(3,2);\n",
    "    print_tex(f'element \\ {i} \\ of \\ C_(i,j)',( a @ C).squeeze(-1).squeeze(-1).numpy())\n",
    "print(f'{C.shape = }')\n",
    "print(f'{a.shape = }')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Because torch Linear() does left matrix-multiply (https://pytorch.org/docs/stable/generated/torch.nn.Linear.html),\n",
    "we might transpose problem so its $C^T\\vec{a}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* apply non-linearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* apply softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
